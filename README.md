
# Anime Face Generation with DCGAN 

##  Project Description
This project implements a **Deep Convolutional Generative Adversarial Network (DCGAN)** to generate **realistic anime-style faces**. The model is trained on the **Anime Face Dataset** from Kaggle and learns the underlying patterns of anime art, producing new synthetic faces.

## Project Structure
├── animefacedataset/ # dataset (unzipped here)
├── dcgan_anime_faces.py # main training script
├── generated_samples_torch/ # final generated images
├── epoch_images_torch/ # images saved per epoch
├── torch_checkpoints/ # saved model weights
├── anime_dcgan_generator.pth # final generator model
├── anime_dcgan_discriminator.pth # final discriminator model

## Dataset
- **Dataset**: [Anime Face Dataset (Kaggle)](https://www.kaggle.com/datasets/splcher/animefacedataset)  
- **Images**: ~63,565 cropped anime face images  
- **Resolution**: Resized to **64×64 RGB**  
- **Loader**: PyTorch `ImageFolder` with transformations (Resize, ToTensor, Normalize)

##  GAN Architecture

### Generator
- Input: 100-dim latent vector (noise `z`)  
- Fully connected → 4x4x1024 feature map  
- Transposed convolutions (`ConvTranspose2d`) with BatchNorm & ReLU  
- Output: 3-channel (RGB) image at 64×64, with `Tanh` activation  

### Discriminator
- Input: 3×64×64 image  
- Convolutions (`Conv2d`) with LeakyReLU & BatchNorm  
- Output: Single sigmoid value (real/fake)  

### Loss Function
- **Binary Cross Entropy (BCE)** for both Generator & Discriminator  
- Optimizer: **Adam** (`lr=0.0002`, `betas=(0.5, 0.999)`)  

## Training Process
1. Discriminator Step:

Process:
Take a batch of real images from the dataset and label them as 1.
Take a batch of fake images generated by the generator and label them as 0.
Pass both batches through the discriminator and calculate the Binary Cross Entropy (BCE) loss.
Update the discriminator’s weights to minimize this loss. 

2. Generator Step:

Process:
Generate a batch of fake images using random noise as input.
Pass these images through the discriminator.
Calculate BCE loss, but with target label as 1 (the generator wants the discriminator to classify its fake images as real).
Update the generator’s weights to minimize this loss.

3. Loss Function:

Binary Cross Entropy (BCE) is used for both:
Discriminator: BCE between real/fake labels and predictions.
Generator: BCE between “real” label (1) and discriminator’s prediction on generated images.

4. Training Parameters:

Batch Size: 128
Epochs: 50 (can increase to 200 for better results)
Checkpoints: Save model weights every 5 epochs

5. Final Models

TorchScript version (anime_dcgan_generator_torchscript.pt).
PyTorch weights (anime_dcgan_generator.pth, anime_dcgan_discriminator.pth).
  

##  Results & Analysis
- Loss stabilized:
  - **Discriminator loss** ≈ 0.5–0.6  
  - **Generator loss** decreased from ~9.0 → ~3.4  
- Generator loss decreased over epochs → better image quality
- Discriminator loss stabilized around 0.5 → equilibrium achieved
- Generated samples started showing **anime face structures** after ~20 epochs.  
- By **epoch 50**, outputs had recognizable face outlines but still contained noise.  

### FID (Fréchet Inception Distance) Evaluation:
- Epoch 10 → 140.5
- Epoch 25 → 65.3
- Epoch 50 → 32.8

 GAN is learning properly.  
 Still needs longer training (100–200 epochs) for sharper details.  

## How to Run

### 1. Clone Repo & Install Requirements
```bash
!git clone https://github.com/your-username/anime-gan-dcgan.git
%cd anime-gan-dcgan
!pip install torch torchvision matplotlib pillow
```

### 2. Run in Google Colab
- Upload the notebook (`.ipynb`) to Colab  
- Download the data set from kaggle and Unzip the dataset
- Set up the path to the dataset

### It's Take more than 1Hr to Epoch Training in Colab

### 3. View Generated Samples
```python
from IPython.display import Image, display
display(Image(filename="epoch_images_torch/epoch_050.png"))
```

## Challenges Faced
- **GAN instability**: Mode collapse & oscillating losses during early epochs.  
- **Training time**: Requires long GPU runtime for high-quality results.  
- **Image quality**: Outputs blurrier than expected with only 50 epochs.  


## Sample Output (Epoch 50)
<img width="438" height="471" alt="image" src="https://github.com/user-attachments/assets/ebef715d-450d-48b9-b62c-b9c1f3d284aa" />
 
